{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-pre-market-gappers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"premarketgaps_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-pre-market-gainers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"premarketgainers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-pre-market-losers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"premarketlosers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-active-pre-market-stocks/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"premarketmostactive_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1541fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-after-hours-gainers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"afterhoursgainers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-after-hours-losers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"afterhourslosers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-active-after-hours-stocks/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"afterhoursmostactive_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-gainers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"topgainers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://www.tradingview.com/markets/stocks-usa/market-movers-losers/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Create the CSV filename\n",
    "csv_filename = f\"toplosers_{current_date}.csv\"\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    header_row = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Write each row of data\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the first row (header)\n",
    "        data_row = [td.text.strip() for td in row.find_all(\"td\")]\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "print(f\"Data has been scraped and saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef74c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samember_flash_gap",
   "language": "python",
   "name": "samember_flash_gap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
