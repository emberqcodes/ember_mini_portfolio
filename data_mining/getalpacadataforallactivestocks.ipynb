{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d541d1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 done!\n",
      "31523\n",
      "Actives done!\n",
      "11129\n",
      "Length of actives is said above!\n",
      "get_intra function understood\n",
      "get_all_intra function with error handling understood\n",
      "get_all_intra function understood\n",
      "get_all_intra_in batches function understood\n"
     ]
    }
   ],
   "source": [
    "# samember_flash_gap\\Scripts\\activate\n",
    "\n",
    "#!pip install alpaca\n",
    "#!pip install alpaca-py\n",
    "#!pip install alpaca-trade-api\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "from alpaca.trading.enums import AssetExchange, AssetStatus, AssetClass\n",
    "\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.enums import Adjustment\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta, time as dt_time\n",
    "import pytz\n",
    "ny = pytz.timezone('America/New_York')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    path = 'C:/Users/pcuser/Documents/GitHub/C9-Research/ftg/code/screener_v2/credentials/apca_live.txt'\n",
    "if os.name == 'posix':\n",
    "    path = '/home/s/Downloads/apca_key.txt'\n",
    "    \n",
    "# # path to live creds \n",
    "# 'ftg/code/screener_v2/credentials/apca_live.txt'\n",
    "\n",
    "key, sec = open(path, 'r').read().split('\\n')\n",
    "\n",
    "trading_client = TradingClient(key, sec)\n",
    "stock_client = StockHistoricalDataClient(key, sec)\n",
    "\n",
    "print(\"Part 1 done!\")\n",
    "\n",
    "#############################################################\n",
    "\n",
    "trading_client = TradingClient(key, sec, raw_data=True, paper=False)\n",
    "equity_assets = trading_client.get_all_assets(\n",
    "    GetAssetsRequest(\n",
    "        # status=AssetStatus.ACTIVE,\n",
    "        asset_class=AssetClass.US_EQUITY,\n",
    "    )\n",
    ")\n",
    "equities_df = pd.DataFrame([asset for asset in equity_assets])\n",
    "print(len(equities_df))\n",
    "\n",
    "#############################################################\n",
    "\n",
    "equities_df['len'] = equities_df['symbol'].apply(lambda x: len(x))\n",
    "# filter warrants\n",
    "equities_df.loc[\n",
    "    equities_df['name'].str.contains(' Warrant'),\n",
    "    'warrant'\n",
    "] = 1\n",
    "equities_df['warrant'] = equities_df['warrant'].fillna(0)\n",
    "# filter acquisition units\n",
    "equities_df.loc[\n",
    "    (equities_df['name'].str.contains(' Acquisition'))\n",
    "    & ((equities_df['name'].str.contains(' Unit'))),\n",
    "    'acq_unit'\n",
    "] = 1\n",
    "equities_df['acq_unit'] = equities_df['acq_unit'].fillna(0)\n",
    "\n",
    "#############################################################\n",
    "\n",
    "actives = equities_df.loc[\n",
    "    (~equities_df['symbol'].str.contains('[0-9]{1,}'))\n",
    "    & (equities_df['exchange'] != 'OTC')\n",
    "    & (equities_df['warrant'] == 0)\n",
    "    & (equities_df['acq_unit'] == 0)\n",
    "    & ~(equities_df['symbol'].str.contains(r'\\.'))\n",
    "    & (equities_df['len'] <= 4),\n",
    "    'symbol'\n",
    "].tolist()\n",
    "\n",
    "print(\"Actives done!\")\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "actives = sorted(set(actives))\n",
    "print(len(actives))\n",
    "\n",
    "print (\"Length of actives is said above!\")\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def get_intra(symbols, start, end):\n",
    "\n",
    "    tf = TimeFrame(1, TimeFrameUnit.Minute)\n",
    "    request_params = StockBarsRequest(\n",
    "        symbol_or_symbols=symbols,\n",
    "        timeframe=tf,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        adjustment=Adjustment.SPLIT,\n",
    "    )\n",
    "    stock_client = StockHistoricalDataClient(key, sec)\n",
    "    bars = stock_client.get_stock_bars(request_params)\n",
    "    bars = bars.df.tz_convert('America/New_York', axis=0, level=1)\n",
    "    \n",
    "    return bars\n",
    "\n",
    "print (\"get_intra function understood\")\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def get_all_intra(tickers, start, end, window=10):\n",
    "    data = pd.DataFrame()\n",
    "    for _ in tqdm(range(int(len(tickers) / window) + 1)):\n",
    "        symbols = list(tickers[_*window:(_+1)*window])\n",
    "        try:\n",
    "            df = get_intra(\n",
    "                symbols=symbols,\n",
    "                start=start,\n",
    "                end=end\n",
    "            )\n",
    "            data = pd.concat([data, df], axis=0)\n",
    "            df.to_parquet(\n",
    "                f'd:/equities_latest/intraday/{symbols[0]}-{symbols[-1]}_{start.date()}-{end.date()}.pq'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for symbols {symbols}: {e}\")\n",
    "            # Optionally, log the error to a file for further analysis\n",
    "            with open(\"error_log.txt\", \"a\") as log_file:\n",
    "                log_file.write(f\"Error fetching data for symbols {symbols}: {e}\\n\")\n",
    "    return data\n",
    "\n",
    "print(\"get_all_intra function with error handling understood\")\n",
    "\n",
    "\n",
    "\n",
    "print (\"get_all_intra function understood\")\n",
    "\n",
    "#############################################################\n",
    "def get_all_intra_in_batches(tickers, start, end, window=10, batch_size=100):\n",
    "    num_batches = len(tickers) // batch_size + (1 if len(tickers) % batch_size > 0 else 0)\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches)):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min((batch_idx + 1) * batch_size, len(tickers))\n",
    "        batch_tickers = tickers[batch_start:batch_end]\n",
    "        \n",
    "        data = pd.DataFrame()\n",
    "        for _ in tqdm(range(int(len(batch_tickers) / window) + 1)):\n",
    "            symbols = list(batch_tickers[_*window:(_+1)*window])\n",
    "            df = get_intra(\n",
    "                symbols=symbols,\n",
    "                start=start,\n",
    "                end=end\n",
    "            )\n",
    "            data = pd.concat([data, df], axis=0)\n",
    "            df.to_parquet(\n",
    "                f'd:/equities_data_2024/intraday/{symbols[0]}-{symbols[-1]}_{start.date()}-{end.date()}.pq'\n",
    "            )\n",
    "        \n",
    "        yield data\n",
    "\n",
    "print (\"get_all_intra_in batches function understood\")\n",
    "#############################################################\n",
    "#############################################################\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a005ddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e403ec3136c547318ed0b8cddeed875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for symbols ['EIO', 'EIP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['EMBH', 'EMBU']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ENBL', 'ENFC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['EQD', 'EQGP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['EQLT', 'EQM']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ESND', 'ESNG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['EUMF', 'EUMV']: The level 1 is not valid\n",
      "Error fetching data for symbols ['FCRZ', 'FCSC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['FXS', 'FXSG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GARD', 'GARS']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GBLO', 'GBNK']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GFY', 'GG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GHII', 'GHIV']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GMZ', 'GNAF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GNMK', 'GNMX']: The level 1 is not valid\n",
      "Error fetching data for symbols ['GTYH', 'GUDB']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HEWL', 'HEWP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HEWW', 'HEWY']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HGH', 'HGI']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HMHC', 'HMLP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HMSY', 'HMTA']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HQBD', 'HQCL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['HYGO', 'HYGS']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IBDK', 'IBDL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IBMG', 'IBMH']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IBMI', 'IBMJ']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ICOL', 'ICON']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IEFN', 'IEHS']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IMDZ', 'IMFI']: The level 1 is not valid\n",
      "Error fetching data for symbols ['INXN', 'INXX']: The level 1 is not valid\n",
      "Error fetching data for symbols ['IPHI', 'IPHS']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ISBC', 'ISCA']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JDD', 'JDIV']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JHD', 'JHDG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JMEI', 'JMF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JMIN', 'JMLP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JNMF', 'JNP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JPEU', 'JPGE']: The level 1 is not valid\n",
      "Error fetching data for symbols ['JPN', 'JPNL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['LEAF', 'LEAP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['LMLB', 'LMLP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['LMNX', 'LMRK']: The level 1 is not valid\n",
      "Error fetching data for symbols ['LOPX', 'LOR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['LTS', 'LTXB']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MACQ', 'MACU']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MBT', 'MBTF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MCF', 'MCFE']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MEN', 'MENV']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MFO', 'MFSF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MJJ', 'MJO']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MLPE', 'MLPG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MLPI', 'MLPQ']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MLPZ', 'MLQD']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MXWL', 'MYC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['MYJ', 'MYL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['NEWA', 'NEWM']: The level 1 is not valid\n",
      "Error fetching data for symbols ['NIFE', 'NIHD']: The level 1 is not valid\n",
      "Error fetching data for symbols ['NYNY', 'NYRT']: The level 1 is not valid\n",
      "Error fetching data for symbols ['OIIL', 'OIL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['OMN', 'OMOM']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ONDK', 'ONDR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PBAU', 'PBB']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PBC', 'PBCT']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PMPT', 'PMR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PPD', 'PPDF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PPLC', 'PPLN']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PQLC', 'PQSG']: The level 1 is not valid\n",
      "Error fetching data for symbols ['PRSP', 'PRSS']: The level 1 is not valid\n",
      "Error fetching data for symbols ['QEP', 'QES']: The level 1 is not valid\n",
      "Error fetching data for symbols ['QXMI', 'QXTR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RDBX', 'RDC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RTL', 'RTLR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RUSS', 'RVEN']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RWCD', 'RWDC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RWDE', 'RWED']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RWGV', 'RWIU']: The level 1 is not valid\n",
      "Error fetching data for symbols ['RWVG', 'RWW']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SBBP', 'SBBX']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SCA', 'SCAC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SCID', 'SCIJ']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SCIU', 'SCIX']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SOJA', 'SOJB']: The level 1 is not valid\n",
      "Error fetching data for symbols ['SREV', 'SRF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['STML', 'STMP']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TACA', 'TACE']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TIER', 'TIF']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TLDH', 'TLEH']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TLMD', 'TLND']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TRCB', 'TRCO']: The level 1 is not valid\n",
      "Error fetching data for symbols ['TSS', 'TST']: The level 1 is not valid\n",
      "Error fetching data for symbols ['UBG', 'UBIO']: The level 1 is not valid\n",
      "Error fetching data for symbols ['UBM', 'UBN']: The level 1 is not valid\n",
      "Error fetching data for symbols ['UCHF', 'UCI']: The level 1 is not valid\n",
      "Error fetching data for symbols ['UZA', 'UZB']: The level 1 is not valid\n",
      "Error fetching data for symbols ['VSI', 'VSL']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WAGE', 'WAIR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WBIB', 'WBIC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WBID', 'WBIE']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WBIN', 'WBIR']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WCG', 'WCGC']: The level 1 is not valid\n",
      "Error fetching data for symbols ['WRD', 'WREI']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ZGNX', 'ZGYH']: The level 1 is not valid\n",
      "Error fetching data for symbols ['ZIXI', 'ZJPN']: The level 1 is not valid\n",
      "Intraday data retrieval and saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n",
    "#get_all_intra function used below: \n",
    "#TO USE: \n",
    "####MODIFY \"start\" and change pd.offsets.BDay(2)) the number after BDay\n",
    "####MODIFY tickers and change tickers = actives[0:1] to the list you want to siphon\n",
    "\n",
    "start = (datetime.today() - pd.offsets.BDay(100))\n",
    "start = datetime.combine(\n",
    "    start,\n",
    "    dt_time(0, 0, tzinfo=ny),\n",
    ")\n",
    "end = datetime.combine(\n",
    "    datetime.now(tz=ny).date(),\n",
    "    dt_time(9, 30, tzinfo=ny)\n",
    ")\n",
    "\n",
    "tickers = actives[2946:11130]\n",
    "window = 2\n",
    "\n",
    "intraday_data = get_all_intra(tickers, start, end, window)\n",
    "\n",
    "# Check if the function executed successfully\n",
    "if intraday_data is not None:\n",
    "    print(\"Intraday data retrieval and saving completed successfully.\")\n",
    "else:\n",
    "    print(\"There was an issue with intraday data retrieval and saving.\")\n",
    "\n",
    "#############################################################\n",
    "#############################################################\n",
    "#############################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a Parquet file into a pandas DataFrame\n",
    "df = pd.read_parquet('D:\\equities_data_2024\\intraday\\AABA-AACG_2022-05-09-2024-04-08.pq')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126ce8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samember_flash_gap",
   "language": "python",
   "name": "samember_flash_gap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
